{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import math\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading audio files and storing the data\n",
    "dev = pd.read_csv('./datasets/development.csv')\n",
    "eval = pd.read_csv('./datasets/evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_age(ds):\n",
    "    #we remove the edge age values\n",
    "    #a = ds.groupby('age')['Id'].count()\n",
    "    ds = ds[(ds['age']>14) & (ds['age']<91)]\n",
    "    ds['age'] = ds['age'].apply(lambda x: math.floor(x))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(ds_dev,ds_eval):\n",
    "    \n",
    "    ds_dev= clean_age(ds_dev)\n",
    "\n",
    "    #concatenation of dev and eval datasets\n",
    "    ds = pd.concat([ds_dev, ds_eval], sort=False)\n",
    "    ds['path'] = 'datasets/' + ds['path']  #change the path for \n",
    "    ds_mask = ~ds[\"age\"].isna()\n",
    "    print('Length of data sets: dev, eval, concat')\n",
    "    print((ds_dev.shape), (ds_eval.shape), (ds.shape))\n",
    "    \n",
    "    #reset index\n",
    "    ds = ds.reset_index().drop(columns=['index'])\n",
    "    ds = ds.drop(columns=['sampling_rate','min_pitch', 'max_pitch', 'Id'])\n",
    "    \n",
    "    #tempo column \n",
    "    if ds['tempo'].dtype != float:\n",
    "        ds['tempo'] = ds['tempo'].apply(lambda x: float(x.lstrip('[').rstrip(']')))\n",
    "        \n",
    "    \n",
    "    ds.loc[ds['gender'] == 'famale', 'gender'] = 'female'\n",
    "    \n",
    "    return ds, ds_dev,ds_eval,ds_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features(file_audio):\n",
    "    y, sr = librosa.load(file_audio)\n",
    "\n",
    "\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    # MFCC\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1) \n",
    "    mfcc_std = np.std(mfcc, axis=1)    \n",
    "    \n",
    "    # Mel-spectrogramma\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=20)\n",
    "    log_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    mel_mean = np.mean(log_spectrogram, axis=1)  \n",
    "    mel_std = np.std(log_spectrogram, axis=1)    \n",
    "    \n",
    "   \n",
    "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "    \n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "\n",
    "  \n",
    "    mean_chroma = np.mean(chroma, axis=1) \n",
    "    std_chroma = np.std(chroma, axis=1) \n",
    "\n",
    "\n",
    "    features = {}\n",
    "    \n",
    "    for i in range(mfcc_mean.shape[0]):\n",
    "        features[f'mfcc_mean_{i+1}'] = mfcc_mean[i]\n",
    "        features[f'mfcc_std_{i+1}'] = mfcc_std[i]\n",
    "\n",
    "\n",
    "    for i in range(mel_mean.shape[0]):\n",
    "        features[f'mel_mean_{i+1}'] = mel_mean[i]\n",
    "        features[f'mel_std_{i+1}'] = mel_std[i]\n",
    "        \n",
    "    for i in range(mean_chroma.shape[0]):\n",
    "        features[f'chroma_mean_{i+1}'] = mean_chroma[i]\n",
    "        features[f'chroma_std_{i+1}'] = std_chroma[i]\n",
    "\n",
    "    features['rolloff'] = spectral_rolloff\n",
    "    features['spectral_bandwidth'] = spectral_bandwidth\n",
    "    features['duration'] = duration\n",
    "\n",
    "\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_extract(path):\n",
    "    f = extract_audio_features(path)\n",
    "    return pd.DataFrame([f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    feature_list = df['path'].apply(extract_audio_features)\n",
    "        \n",
    "    features_df = pd.DataFrame(feature_list.to_list())\n",
    "\n",
    "    df = pd.concat([df, features_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_path(df):\n",
    "    #storing the paths\n",
    "    df = df.drop(columns=['path'])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encoding(df,to_encode):\n",
    "    df_dumm = pd.get_dummies(df, columns=to_encode)\n",
    "    print(\"Shape: dumm \",df_dumm.shape)\n",
    "    return df_dumm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_detection(df_dumm,df_mask):\n",
    "   \n",
    "    df_mask=np.reshape(df_mask.values, newshape=df_dumm.shape[0])\n",
    "    df_dev = df_dumm.loc[df_mask,:]\n",
    "    df_eval = df_dumm.loc[~df_mask,:]\n",
    "\n",
    "\n",
    "    print(df_mask)\n",
    "\n",
    "\n",
    "    #df_eval = df_eval.reset_index()\n",
    "    print('Dev iniziale:', df_dev.shape)\n",
    "    print('Eval iniziale:', df_eval.shape)\n",
    "    upper_limit = df_dev.mean(axis=0) + 3*df_dev.std(axis=0)\n",
    "    lower_limit = df_dev.mean(axis=0) - 3*df_dev.std(axis=0)\n",
    "\n",
    "\n",
    "    n=15\n",
    "    count_filtro = (df_dev > upper_limit).sum(axis=1)\n",
    "    filtro=count_filtro>n\n",
    "    df_filtrato_up= df_dev.loc[filtro]\n",
    "    df_up_index = df_filtrato_up.index\n",
    "    print('Righe droppate up:', len(df_filtrato_up))\n",
    "    #age_up = df_filtrato_up.groupby('age')['Id'].count()\n",
    "\n",
    "    count_filtro = (df_dev < lower_limit).sum(axis=1)\n",
    "    filtro=count_filtro>n\n",
    "    df_filtrato_down = df_dev.loc[filtro]\n",
    "    df_down_index = df_filtrato_down.index\n",
    "\n",
    "    print('Righe droppate down:', len(df_filtrato_down))\n",
    "    #age_down = df_filtrato_down.groupby('age')['Id'].count()\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.bar(height=age_up, x = age_up.index)\n",
    "    # plt.figure()\n",
    "\n",
    "    # plt.bar(height = age_down, x = age_down.index)\n",
    "\n",
    "\n",
    "\n",
    "    indexes = np.concatenate((df_down_index, df_up_index))\n",
    "    print('Mask iniziale',len(df_mask))\n",
    "    \n",
    "    df_dev = df_dev.drop(index=indexes)\n",
    "    df_mask = np.delete(df_mask, indexes)\n",
    "    \n",
    "    print('Dev e mask finale', df_dev.shape, len(df_mask))\n",
    "\n",
    "    df_dumm= pd.concat([df_dev, df_eval], sort=False)\n",
    "    print('Dumm final:', df_dumm.shape)\n",
    "\n",
    "    df_dumm = df_dumm.reset_index().drop(columns=['index'])\n",
    "    \n",
    "    return df_dumm, df_dev, df_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning, preprocessing, set\n",
    "def main():\n",
    "    df,df_dev,df_eval,df_mask=clean_dataset(dev,eval)\n",
    "\n",
    "    df= extract_features(df)\n",
    "\n",
    "    df=clean_path(df)\n",
    "\n",
    "    df_dumm=hot_encoding(df,[\"ethnicity\",\"gender\"])\n",
    "\n",
    "    df_dumm, df_dev, df_mask = outliers_detection(df_dumm,df_mask)\n",
    "\n",
    "\n",
    "    df_dumm.to_csv('./data_completi/df_tot.csv', index=False, header=True)\n",
    "    df_dev.to_csv('./data_completi/dev.csv', index=False, header=True)\n",
    "    df_eval.to_csv('./data_completi/eval.csv', index=False, header=True)\n",
    "    df_mask=pd.DataFrame(df_mask)\n",
    "    df_mask.to_csv('./data_completi/mask.csv', index=False)\n",
    "\n",
    "    return df_dumm, np.reshape(df_mask.values, newshape=df_dumm.shape[0]), df_dev, df_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for generating a graph that shows the duration of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_duration = []\n",
    "# for i in range(1,2900):\n",
    "#     d = test_extract(f'./datasets/audios_development/{i}.wav')['duration']\n",
    "#     list_duration.append(d)\n",
    "\n",
    "# s = pd.DataFrame([i[0].round() for i in list_duration], columns=['duration'])\n",
    "# a = s.groupby('duration')['duration'].count()\n",
    "# a.plot(kind='bar', figsize=(10, 6));\n",
    "# plt.yscale(\"log\")\n",
    "# plt.ylabel('Count [log scale]');\n",
    "# plt.xlabel('Duration [s]')\n",
    "# ticks = plt.gca().get_xticks()  \n",
    "# tens_ticks = [tick for tick in ticks if tick % 10 == 0]  \n",
    "# plt.xticks(tens_ticks, rotation=0)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
